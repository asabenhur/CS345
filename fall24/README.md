
# Fall24 Notebooks for CS345: Machine learning Foundations and Practice

<img style="padding: 10px; float:right;" alt="CC-BY-SA icon.svg in public domain" src="https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png" width="75">

This repository contains a set of Jupyter notebooks for Colorado State University's introductory machine learning course [CS345: Machine Learning Foundations and Practice](https://www.cs.colostate.edu/~cs345/).

<img style="padding: 10px; float:right;" alt="CSU" src="https://static.colostate.edu/logo/reslogo-v2/assets/img/csu-responsive-symbol.min.svg" width="1500">

### Table of Contents

The notebooks for this course are divided into the following modules:

* Preliminaries:
  * [Course introduction](notebooks/module00_01_intro.ipynb) 
  * [A brief introduction to Python](notebooks/module00_02_python_intro.ipynb)
  * [NumPy](notebooks/module00_03_numpy.ipynb)
  * [Visualizing data with Matplotlib](notebooks/module00_04_matplotlib.ipynb)
* Vectors, matrices, dot products, hyperplanes and the perceptron
  * [Labeled data and supervised learning](notebooks/module01_01_labeled_data.ipynb)
  * [Vectors](notebooks/module01_02_vectors.ipynb)
  * [Dot products](notebooks/module01_03_dot_products.ipynb)	
  * [Hyperplanes](notebooks/module01_04_hyperplanes.ipynb)
  * [Matrices](notebooks/module01_05_matrices.ipynb)
  * [Our first classifier:  The perceptron](notebooks/module01_06_perceptron.ipynb)
* More classifiers: nearest neighbors, SVMs; principal components analysis
  * [Nearest neighbor classification](notebooks/module02_01_nearest_neighbors.ipynb)
  * [Nearest neighbor classification (part 2)](notebooks/module02_02_more_nearest_neighbors.ipynb)
  * [Principal components analysis (PCA)](notebooks/module02_03_pca.ipynb)
  * [Support vector machines (SVM)](notebooks/module02_04_svm.ipynb)
* Linear regression
  * [From classification to regression](notebooks/module03_01_nn_to_regression.ipynb) 
  * [Linear regression](notebooks/module03_02_linear_regression.ipynb)
  * [Derivatives and partial derivatives](notebooks/module03_03_derivatives_partial_derivatives.ipynb)
  * [Multivariate linear regression](notebooks/module03_04_multivariate_linear_regression.ipynb)
  * [Solving linear regression with gradient descent](notebooks/module03_05_linear_regression_gradient_descent.ipynb)
* Overfitting and regularization
  * [Basis function regression and overfitting](notebooks/module04_01_overfitting_basis_function_regression.ipynb)
  * [Regularization](notebooks/module04_02_regularization.ipynb)
  * [Kernels and regularization for non-linear SVMs](notebooks/module04_03_kernels.ipynb)
* Classifier evaluation
  * [Hyperparameters and the validation set](notebooks/module05_hyperparameters_validation.ipynb)
  * [Cross-validation](notebooks/module05_02_cross_validation.ipynb)
  * [Model selection and nested cross-validation](notebooks/module05_03_model_selection.ipynb) 
  * [Measuring classifier
    accuracy](notebooks/module05_04_classifier_accuracy.ipynb)
  * [Multi-class classification](notebooks/module05_05_multiclass.ipynb)
* Decision trees, ensemble methods, and random forests
  * [Decision trees](notebooks/module06_01_decision_trees.ipynb)
  * [Ensemble methods and random forests](notebooks/module06_02_ensemble_methods.ipynb)
* Neural networks
  * [An introduction to feed forward networks](notebooks/module07_01_neural_networks_mlp.ipynb)
  * [Feed forward networks with keras](notebooks/module07_02_neural_networks_keras.ipynb)
  * [Image classification using feed forward neural networks](notebooks/module07_03_neural_networks_mnist.ipynb)
* Conclusions
    * [Running and describing machine learning experiments](notebooks/module08_01_running_and_describing_ml_experiments.ipynb)
    * [Course summary](notebooks/module08_02_conclusions.ipynb)
